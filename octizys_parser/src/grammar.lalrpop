use std::str::FromStr;
use octizys_cst::{
  base::{Between,Token,TrailingList,TokenInfo,ImportedVariable,OperatorName,TrailingListItem},
  comments::{CommentKind,LineCommentStart,Comment},
  imports::{Import},
  types::{Type,TypeRecordItem,TypeBase},
  patterns::{PatternMatch,PatternMatchRecordItem, PatternMatchBind},
  expressions::{Expression,CaseItem,Case,ExpressionSelector,ExpressionRecordItem}};
use octizys_cst::base;
use octizys_common::module_logic_path::ModuleLogicPath;
use octizys_common::identifier::Identifier;
use octizys_common::span::Position;
use crate::lexer;

grammar;

// All tokens already have the information of the comments
// right before them and right after them in the same line.
// The different parts of the CST (Concret Syntax Tree)
// may choose to move them a little above to be part of the
// comments of a piece of the CST.
// This will have a global effect in the formatter.

extern {
    type Location = Position;
    type Error = lexer::LexerError;

    enum lexer::Token {
      "?" => lexer::Token::Interrogation(TokenInfo)
      ,"!" => lexer::Token::Exclamation(TokenInfo)
      ,"#" => lexer::Token::Hash(TokenInfo)
      ,"," => lexer::Token::Comma(TokenInfo)
      ,":" => lexer::Token::Colon(TokenInfo)
      ,";" => lexer::Token::StatementEnd(TokenInfo)
      ,"." => lexer::Token::Dot(TokenInfo)
      ,"::" => lexer::Token::ModuleSeparator(TokenInfo)
      ,"-" => lexer::Token::Minus(TokenInfo)
      ,"|>" => lexer::Token::CompositionLeft(TokenInfo)
      ,"<|" => lexer::Token::CompositionRight(TokenInfo)
      ,"+" => lexer::Token::Plus(TokenInfo)
      ,"^" => lexer::Token::Power(TokenInfo)
      ,"*" => lexer::Token::Star(TokenInfo)
      ,"/" => lexer::Token::Div(TokenInfo)
      ,"%" => lexer::Token::Module(TokenInfo)
      ,"<<" => lexer::Token::ShiftLeft(TokenInfo)
      ,">>" => lexer::Token::ShiftRigth(TokenInfo)
      //TODO: Add "<&>" = \ x y -> y $ x
      ,"<$>" => lexer::Token::Map(TokenInfo)
      ,"$>" => lexer::Token::MapConstRigth(TokenInfo)
      ,"<$" => lexer::Token::MapConstLeft(TokenInfo)
      //TODO: add <|> and <?>
      ,"<*>" => lexer::Token::Appliative(TokenInfo)
      ,"*>" => lexer::Token::ApplicativeRight(TokenInfo)
      ,"<*" => lexer::Token::ApplicativeLeft(TokenInfo)
      ,"==" => lexer::Token::Equality(TokenInfo)
      ,"!=" => lexer::Token::NotEqual(TokenInfo)
      ,"<=" => lexer::Token::LessOrEqual(TokenInfo)
      ,">=" => lexer::Token::MoreOrEqual(TokenInfo)
      ,"<" => lexer::Token::LessThan(TokenInfo)
      ,">" => lexer::Token::MoreThan(TokenInfo)
      ,"&&" => lexer::Token::And(TokenInfo)
      ,"||" => lexer::Token::Or(TokenInfo)
      ,"&" => lexer::Token::ReverseAppliation(TokenInfo)
      ,"$" => lexer::Token::DollarApplication(TokenInfo)
      ,"=" => lexer::Token::Asignation(TokenInfo)
      ,"@" => lexer::Token::At(TokenInfo)
      ,"|" => lexer::Token::Pipe(TokenInfo)
      ,"(" => lexer::Token::LParen(TokenInfo)
      ,")" => lexer::Token::RParen(TokenInfo)
      ,"{" => lexer::Token::LBrace(TokenInfo)
      ,"}" => lexer::Token::RBrace(TokenInfo)
      ,"[" => lexer::Token::LBracket(TokenInfo)
      ,"]" => lexer::Token::RBracket(TokenInfo)
      ,"->" => lexer::Token::RightArrow(TokenInfo)
      ,"<-" => lexer::Token::LeftArrow(TokenInfo)
      ,"\\" => lexer::Token::LambdaStart(TokenInfo)
      ,"let" => lexer::Token::Let(TokenInfo)
      ,"in" => lexer::Token::In(TokenInfo)
      ,"case" => lexer::Token::Case(TokenInfo)
      ,"of" => lexer::Token::Of(TokenInfo)
      ,"import" => lexer::Token::Import(TokenInfo)
      ,"export" => lexer::Token::Export(TokenInfo)
      ,"data" => lexer::Token::Data(TokenInfo)
      ,"newtype" => lexer::Token::Newtype(TokenInfo)
      ,"newinstance" => lexer::Token::Newtype(TokenInfo)
      ,"class" => lexer::Token::Newtype(TokenInfo)
      ,"instance" => lexer::Token::Newtype(TokenInfo)
      ,"public" => lexer::Token::Newtype(TokenInfo)
      ,"alias" => lexer::Token::Alias(TokenInfo)
      ,"as" => lexer::Token::As(TokenInfo)
      ,"unqualified" => lexer::Token::Unqualified(TokenInfo)
      ,"forall" => lexer::Token::Forall(TokenInfo)
      ,"type" => lexer::Token::Type(TokenInfo)
      ,U8 => lexer::Token::U8(TokenInfo)
      ,U16 => lexer::Token::U16(TokenInfo)
      ,U32 => lexer::Token::U32(TokenInfo)
      ,U64 => lexer::Token::U64(TokenInfo)
      ,I8 => lexer::Token::I8(TokenInfo)
      ,I16 => lexer::Token::I16(TokenInfo)
      ,I32 => lexer::Token::I32(TokenInfo)
      ,I64 => lexer::Token::I64(TokenInfo)
      ,F32 => lexer::Token::F32(TokenInfo)
      ,F64 => lexer::Token::F64(TokenInfo)
      ,CharType => lexer::Token::CharType(TokenInfo)
      ,StringType => lexer::Token::StringType(TokenInfo)
      ,LastComments=> lexer::Token::LastComments(TokenInfo,Comment)
      ,StringLiteral => lexer::Token::StringLiteral(TokenInfo,String)
      ,CharacterLiteral => lexer::Token::CharacterLiteral(TokenInfo,String)
      ,UintLiteral => lexer::Token::UintLiteral(TokenInfo,String)
      ,UFloatLiteral=> lexer::Token::UFloatLiteral(TokenInfo,String)
      ,Identifier=> lexer::Token::Identifier(TokenInfo,String)
      ,InfixIdentifier=> lexer::Token::InfixIdentifier(TokenInfo,String)
      ,Selector=> lexer::Token::Selector(TokenInfo,String)
      ,"_"=> lexer::Token::AnonHole(TokenInfo,String)
      ,NamedHole=> lexer::Token::NamedHole(TokenInfo,u64)
      ,ModuleLogicPath=> lexer::Token::ModuleLogicPath(TokenInfo,String)
    }
}

// --------------------- Macros ---------------------

separated_list<T,sep>: TrailingList<T> ={
  <t:T> <mut acc: (sep T)*>=> (t,acc,None).into()
  };

terminated_list<T,sep> : TrailingList<T> =
  <t:T> <mut acc: (sep T)*> <s:sep>=> (t,acc,Some(s)).into();

trailing_list<T,sep> : TrailingList<T> = {separated_list<T,sep>,terminated_list<T,sep>}

between<left,T,right> : Between<T> =
  <l:left> <t:T> <r:right>
  => Between{left:l.into(),right:r.into(),value:t};

tuple<T> : Between<TrailingList<T>> = {
  between<"(",terminated_list<T,",">,")"> => <>,
};

record<record_item, sep> : Between<TrailingList<record_item>> = {
  between<"{",trailing_list<record_item,sep>,"}"> => <>,
};

boxed<T> : Box<T> = T => Box::new(<>);

// --------------------- Terminal translation ---------------------

pub string :Token<String> = StringLiteral =>? lexer::string_token_to_token(<>);

character : Token<char> = CharacterLiteral =>? lexer::char_token_to_token(<>);

uint : Token<String> = UintLiteral =>? lexer::uint_token_to_token(<>);

ufloat : Token<String> = UFloatLiteral =>? lexer::ufloat_token_to_token(<>);

module_path : Token<ModuleLogicPath>  =
  ModuleLogicPath =>? lexer::module_token_to_token(<>);

identifier : Token<Identifier> = Identifier =>? lexer::identifier_token_to_token(<>);
operator_name : Token<OperatorName> = {
      "?" => base::Token{value: OperatorName::Interrogation,info:<>.into()}
      ,"!" => base::Token{value: OperatorName::Exclamation,info:<>.into()}
      ,"#" => base::Token{value: OperatorName::Hash,info:<>.into()}
      ,"," => base::Token{value: OperatorName::Comma,info:<>.into()}
      ,":" => base::Token{value: OperatorName::Colon,info:<>.into()}
      ,";" => base::Token{value: OperatorName::StatementEnd,info:<>.into()}
      ,"." => base::Token{value: OperatorName::Dot,info:<>.into()}
      ,"::" => base::Token{value: OperatorName::ModuleSeparator,info:<>.into()}
      ,"-" => base::Token{value: OperatorName::Minus,info:<>.into()}
      ,"|>" => base::Token{value: OperatorName::CompositionLeft,info:<>.into()}
      ,"<|" => base::Token{value: OperatorName::CompositionRight,info:<>.into()}
      ,"+" => base::Token{value: OperatorName::Plus,info:<>.into()}
      ,"^" => base::Token{value: OperatorName::Power,info:<>.into()}
      ,"*" => base::Token{value: OperatorName::Star,info:<>.into()}
      ,"/" => base::Token{value: OperatorName::Div,info:<>.into()}
      ,"%" => base::Token{value: OperatorName::Module,info:<>.into()}
      ,"<<" => base::Token{value: OperatorName::ShiftLeft,info:<>.into()}
      ,">>" => base::Token{value: OperatorName::ShiftRigth,info:<>.into()}
      //TODO: Add "<&>" = \ x y -> y $ x
      ,"<$>" => base::Token{value: OperatorName::Map,info:<>.into()}
      ,"$>" => base::Token{value: OperatorName::MapConstRigth,info:<>.into()}
      ,"<$" => base::Token{value: OperatorName::MapConstLeft,info:<>.into()}
      //TODO: add <|> and <?>
      ,"<*>" => base::Token{value: OperatorName::Appliative,info:<>.into()}
      ,"*>" => base::Token{value: OperatorName::ApplicativeRight,info:<>.into()}
      ,"<*" => base::Token{value: OperatorName::ApplicativeLeft,info:<>.into()}
      ,"==" => base::Token{value: OperatorName::Equality,info:<>.into()}
      ,"!=" => base::Token{value: OperatorName::NotEqual,info:<>.into()}
      ,"<=" => base::Token{value: OperatorName::LessOrEqual,info:<>.into()}
      ,">=" => base::Token{value: OperatorName::MoreOrEqual,info:<>.into()}
      ,"<" => base::Token{value: OperatorName::LessThan,info:<>.into()}
      ,">" => base::Token{value: OperatorName::MoreThan,info:<>.into()}
      ,"&&" => base::Token{value: OperatorName::And,info:<>.into()}
      ,"||" => base::Token{value: OperatorName::Or,info:<>.into()}
      ,"&" => base::Token{value: OperatorName::ReverseAppliation,info:<>.into()}
      ,"$" => base::Token{value: OperatorName::DollarApplication,info:<>.into()}
      ,"=" => base::Token{value: OperatorName::Asignation,info:<>.into()}
      ,"@" => base::Token{value: OperatorName::At,info:<>.into()}
      ,"|" => base::Token{value: OperatorName::Pipe,info:<>.into()}
      ,"->" => base::Token{value: OperatorName::RightArrow,info:<>.into()}
      ,"<-" => base::Token{value: OperatorName::LeftArrow,info:<>.into()}
      ,"\\" => base::Token{value: OperatorName::LambdaStart,info:<>.into()}
};

selector : Token<Identifier> = Selector =>? lexer::selector_token_to_token(<>);

//We can hack the lexer to do the split of the path from the
//head, but we choose to do this instead.
//We may consider the other approach if we get a conflict in lalrpop.
imported_variable : Token<ImportedVariable> =
  module_path => {
  todo!()
  //let (maybe_remain,head) = <>.split_head();
  //// The regex in the lexer is `(identifier ::)+ identifier`
  //let remain = maybe_remain.unwrap();
  //NamedVariable::PrefixedVariable{prefix:remain,name:head}
  };

//The comments right before or after the last :: are moved to be before the
// module prefix and we do the same to the before comments on the operator.
// The only part of the operator comments that is preserved is the after
// comment if it exists.
// ```
// {- original comment before -}
// a::b::c -- some comment0
//   -- some comment1
//   :: -- some comment2
// {- some comment3 -}
//      +++  -- some comment4
// ```
// Becomes
// ```
// {- original comment before -}
// -- some comment0
// -- some comment1
// -- some comment2
// {- some comment3 -}
// a::b::c::++ -- some comment4
// ```
// in the CST
// Note that the lexer prevents comments before or after the others ::

local_variable : Token<Identifier> =
  identifier => <>
  ;



import_item : Token<Identifier> ={
  local_variable => <>,
};


// --------------------- Imports ---------------------

//TODO: Add importation of constructors


import_list : TrailingList<Token<Identifier>> =
  trailing_list<import_item,","> => <>;

import_as : (TokenInfo,Token<ModuleLogicPath>) =
  <a:"as"> <p:module_path>
  => (a.into(),p);

pub import_declaration : Import =
  <import:"import"> <unqualified:"unqualified"?> <module_path:module_path>
  <import_list:between<"(",<l:import_list>,")">?>
  <qualified_path:import_as?>
  => Import{
    import:import.into(),
    unqualified:unqualified.map(|x| x.into())
    ,module_path,import_list,qualified_path};


//TODO: add kinds,
// we eventually would add type functions
// and for them enforce a termination checker
// Kinds would be useful for that.
// Additionally consider if we would add effects!

//Types

type_base : Token<TypeBase> = {
  U8 => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::U8,info}
    },
  U16 => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::U16,info}
    },
  U32 => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::U32,info}
    },
  U64 => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::U64,info}
    },
  I8 => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::I8,info}
    },
  I16 => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::I16,info}
    },
  I32 => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::I32,info}
    },
  I64 => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::I64,info}
    },
  F32 => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::F32,info}
    },
  F64 => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::F64,info}
    },
  CharType => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::Char,info}
    },
  StringType => {
    let info :TokenInfo = <>.into();
    base::Token{value:TypeBase::String,info}
    },
};

type_variable : Type = {
  local_variable => Type::LocalVariable(<>),
  imported_variable =>Type::ImportedVariable(<>),
};

type_tuple : Type = {
  tuple<boxed<type_expression>> => Type::Tuple(<>),
}

//TODO: add support for keyword scape
type_record_item : TypeRecordItem = {
  <variable:local_variable> <separator:":"> <expression:type_expression>
  => TypeRecordItem{
    variable,separator:separator.into(),expression:Box::new(expression)
  },
};

//TODO: add support for row polymorphism (we need kinds)
// we may need a different rule than the macro `record`
type_record : Between<TrailingList<TypeRecordItem>> = {
  record<type_record_item, ",">
};

type_atom : Type = {
  type_base => Type::Base(<>),
  type_variable => <>,
  type_tuple => <>,
  type_record => Type::Record(<>),
  <l:"("> <t:type_expression> <r:")"> => Type::Parens(
    Between{
    left : l.into(),
    right : r.into(),
    value: Box::new(t)
    }
  ),
};

type_application : Type = {
   <start:type_atom>
   <second:type_atom>
   <remain:type_atom*> => {
    Type::Application{
      start: Box::new(start) ,
      second: Box::new(second),
      remain
    }
   },
   type_atom => <>,
};

type_arrow : Type = {
  <first:type_application> <remain:("->" type_application)+>
    =>
    Type::Arrow{
      first:Box::new(first),
      remain:remain.into_iter().map(|(x,y)| TrailingListItem{separator:x.into(),item:y}  ).collect()
    },
  type_application => <>
};

type_scheme : Type = {
  <forall:"forall">
    <first_variable:local_variable>
    <remain_variables:local_variable*>
    <dot:".">
    <expression:type_arrow> => {
      Type::Scheme{
        forall: forall.into(),
        first_variable,
        remain_variables,
        dot: dot.into(),
        expression:Box::new(expression)
      }

    },
  type_arrow => <>
};

//TODO : add type operators
pub type_expression : Type = {
  type_scheme => <>,
};



// --------------------- PatternMatch  ---------------------

pattern_variable : PatternMatch = {
  local_variable => PatternMatch::LocalVariable(<>),
  imported_variable => PatternMatch::ImportedVariable(<>),
};

//TODO: add support for negative integers?
pattern_literal : PatternMatch  = {
  string => PatternMatch::String(<>),
  character => PatternMatch::Char(<>),
};

pattern_hole : PatternMatch = {
  "_" => PatternMatch::AnonHole(<>.into()),
};

pattern_tuple :PatternMatch = {
  tuple<boxed<pattern>> => PatternMatch::Tuple(<>),
};

pattern_record_item : PatternMatchRecordItem = {
  <l:local_variable> <r:("=" pattern )?>  =>
  match r {
    Some((equal,p))
      => PatternMatchRecordItem::WithPattern{
        variable:l,
        separator:equal.into(),
        pattern:Box::new(p)
        },
    None => PatternMatchRecordItem::OnlyVariable{variable:l}
  }
  ,
}

//TODO:Add and `...` pattern for `the remaining of the record`.
pattern_record :PatternMatch = {
  between<"{", trailing_list<pattern_record_item,",">,"}">
    => PatternMatch::Record(<>) ,
};


pattern_atom : PatternMatch = {
  pattern_literal => <>,
  pattern_variable => <>,
  pattern_hole => <>,
  pattern_tuple => <>,
  pattern_record => <>,
  between<"(",boxed<pattern>,")">
  => PatternMatch::Parens(<>) ,
};

pattern_bind : PatternMatch = {
  <variable:local_variable> <at:"@"> <pattern:pattern_atom>
    => PatternMatch::Bind(
      PatternMatchBind{
        variable,
        at:at.into(),
        pattern:Box::new(pattern)
      }
    ) ,
  pattern_atom =><>,
}

pattern_application :PatternMatch = {
  <s:pattern_variable> <s2:pattern_bind> <r:pattern_bind*>
    => PatternMatch::Application{
      start: Box::new(s),
      second: Box::new(s2),
      remain: r
    },
  pattern_bind => <>
};

pub pattern : PatternMatch = {
  pattern_application => <>,
};



// --------------------- Expression ---------------------

expression_literal : Expression ={
  string => Expression::String(<>),
  character => Expression::Character(<>),
  uint =>Expression::Uint(<>),
  ufloat => Expression::UFloat(<>),
};

expression_variable : Expression = {
  local_variable => Expression::LocalVariable(<>),
  imported_variable => Expression::ImportedVariable(<>),
};

expression_named_hole : Expression = {
  NamedHole =>? {
    let hole =lexer::named_hole_token_to_token(<>)?;
    Ok(Expression::NamedHole(hole))
    }
};

expression_tuple : Expression = {
  tuple<boxed<expression>> => Expression::Tuple(<>),
};

expression_record_item : ExpressionRecordItem = {
  <v:local_variable> <r:("=" expression)?>
  =>
  match r {
    Some((eq,e)) =>
    ExpressionRecordItem::Assignation{
      variable:v,
      equal:eq.into(),
      expression:Box::new(e),
    },
    None => ExpressionRecordItem::SingleVariable{variable:v},
  }
};

expression_record : Expression = {
  between<"{", trailing_list<expression_record_item,",">,"}">
    => Expression::Record(<>),
}

case_item : CaseItem = {
  <p:pattern> <arrow:"->"> <e:expression>
    => CaseItem{pattern:p,arrow:arrow.into(),expression:Box::new(e)}
}

//The of is needed for this:
// case some_func {a:1 , b:2} { something ...}
// the lr can't choose between
// case (some_func {a:1 , b:2}) { something ...}
// and
// (case some_func {a:1 , b:2}) { something ...}
expression_case : Expression = {
  <c:"case">
  <e:expression>
  <o:"of">
  <remain: between<"{",trailing_list<case_item,",">,"}">>
    => Expression::Case(
      Case{
        case:c.into(),
        expression: Box::new(e),
        of: o.into(),
        cases:remain
      }
    ),
}


expression_atom : Expression = {
  expression_literal => <>,
  expression_variable => <>,
  expression_named_hole => <>,
  expression_tuple => <>,
  expression_record => <>,
  expression_case => <>,
  between<"(",boxed<expression>,")">
    => Expression::Parens(<>) ,
};

//TODO: will the current structure handle?
// `a.b.c.d?.j.t`
// Answer: No, it needs to be put as :
// `(a.b.c.d?).j.t
expression_selector : Expression = {
  <e:expression_atom> <s:(selector "?"?)> <remain:(selector "?"? )*>
    => {
      let (s2, symbol) = s;
      let first = Expression::selector_from_args(Box::new(e),s2,symbol.map(|x| x.into()));
      let mut x : Box<Expression> = Box::new(first);
      for (s3,i) in remain.into_iter(){
        x = Box::new(Expression::selector_from_args(x,s3,i.map(|y| y.into())));
      }
      *x
    },
}

expression_argument : Expression = {
  <at:"@"> <a:type_atom> => Expression::TypeArgument{at:at.into(),_type:a},
  expression_selector =><>,
  <e:expression_atom> <i:"?"?>
    =>
    match i {
      Some(t)
        => Expression::Interrogation{expression:Box::new(e),symbol:t.into()},
      None=> e
    }
}

expression_application : Expression = {
  expression_selector expression_argument* => todo!(),
  expression_atom expression_argument* => todo!()
}

pub expression = expression_application;

/*

expression_infix_application : Expression = {
  expression_application (InfixIdentifier expression_application)? => todo!(),
}

expression_unary_operator : Expression = {
  "-" expression_infix_application => todo!(),
  "!" expression_infix_application => todo!(),
  "#" expression_infix_application => todo!(),
}

expression_composition : Expression = {
  (expression_unary_operator "|>")+ expression_unary_operator => todo!(),
  (expression_unary_operator "<|")+ expression_unary_operator => todo!(),
  expression_unary_operator => todo!(),
}

expression_exponentiation : Expression = {
  expression_composition ("^" expression_composition)? => todo!(),
}


multiplicative_operators  : Token = {
  "*" => todo!(),
  "/" => todo!(),
  "%" => todo!(),
}

expression_multiplicative : Expression = {
  expression_exponentiation
  multiplicative_operators
  expression_exponentiation
  => todo!(),
}

additive_operators : Token = {
  "+" => todo!(),
  "-" => todo!(),
}

expression_additive : Expression = {
  (expression_multiplicative additive_operators)* expression_multiplicative => todo!(),
}

expression_shift : Expression = {
  expression_additive "<<" expression_additive => todo!(),
  expression_additive ">>" expression_additive=>todo!(),
  expression_additive => todo!(),
};

expression_annotation : Expression = {
  expression_shift ":" type_expression => todo!(),
  expression_shift => todo!(),
}


functor_applicative_operators : Token<OperatorName> = {
  "<$>" => todo!(),
  "$>" => todo!(),
  "<$" => todo!(),
  "<*>" => todo!(),
  "<*" => todo!(),
  "*>" => todo!(),
}

expression_functor_applicative : Expression = {
  (expression_annotation functor_applicative_operators)* expression_annotation => todo!(),
}

comparison_operators : Token<OperatorName> = {
  "==" => todo!(),
  "!=" => todo!(),
  "<=" => todo!(),
  ">=" => todo!(),
};

expression_comparison : Expression ={
  expression_functor_applicative
  comparison_operators
  expression_functor_applicative
  =>todo!(),
}

expression_and : Expression ={
  expression_comparison ("&&" expression_comparison)* =>todo!(),
}

expression_or : Expression = {
  expression_and ("||" expression_and)* =>todo!(),
}

expression_reverse_application : Expression = {
  (expression_composition "&")* expression_composition => todo!(),
}

expression_dollar : Expression = {
  expression_reverse_application ("$" expression_reverse_application)* => todo!()
}

// was using pattern_atom+ or separating the patterns using something like ","
// I like this more.
expression_lambda : Expression = {
  "\\" pattern_atom+ "->" expression_dollar => todo!(),
  expression_dollar => todo!(),
}

let_binding : Expression = {
  pattern (":" type_expression)? "=" expression => todo!(),
}

let_bindings : Expression = {
  trailing_list<let_binding,","> =>todo!(),
}

expression_let : Expression = {
  "let" let_bindings "in" expression => todo!(),
  expression_lambda => todo!()
}

pub  expression : Expression = {
  expression_let
};


// --------------------- Data  ---------------------


pub data_type : Data = {
  "public"? "data" local_variable local_variable* "=" separated_list<(local_variable type_expression),"|">
  "public"? "data" local_variable local_variable* "="
}

pub alias : Alias = {
  "public"? "alias" local_variable local_variable* "=" type_expression
}

pub newtype : NewType = {
  "public"? "newtype" local_variable local_variable* "=" local_variable type_expression
}

pub new_instance : NewInstance = {
  "public"? "newinstance" local_variable local_variable* "=" local_variable type_expression
}


// --------------------- Class  ---------------------

//TODO: do classes need pub control?
//TODO: Support for predefined values?
//TODO: Class Constrains?
pub class : Class = {
  "public"? "class" local_variable local_variable* between<"{",trailing_list<function_declaration,",">,"}">
}


//TODO: Add support to declare the explicit type of the function
pub instance : Instance = {
  "public"? "instance" local_variable local_variable local_variable between<"{",trailing_list<function_definition,",">,"}">
  "public"? "instance" operator_name local_variable local_variable between<"{",trailing_list<function_definition,",">,"}">
  "public"? "instance" operator_name local_variable between<"{",trailing_list<function_definition,",">,"}">
}

// --------------------- Functions  ---------------------

pub function_declaration : FunctionDeclaration = {
  local_variable ":" type_expression
}


//TODO: replace local_variable* with pattern_atom*
// ie, support for patterns
pub function_definition : FunctionDefinition = {
  local_variable local_variable* "=" expression
}



pub top_non_import_item : TopItem = {
  data_type,
  alias,
  newtype,
  new_instance,
}

pub top : Cst = {
  terminated_list<import_declaration,";">?
  terminated_list<top_non_import_item,";">?
  LastComments?
}
*/
