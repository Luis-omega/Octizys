use std::str::FromStr;
use octizys_cst::cst::{Between,Token,TrailingList,TokenInfo,CommentKind,LineCommentStart,Comment,ImportItem,Import,NamedVariable,Type,TypeRecordItem,PatternMatch,ImportedVariable,TypeBase,OperatorName};
use octizys_cst::cst;
use octizys_common::module_logic_path::ModuleLogicPath;
use octizys_common::identifier::Identifier;
use crate::lexer;

grammar;

// All tokens already have the information of the comments
// right before them and right after them in the same line.
// The different parts of the CST (Concret Syntax Tree)
// may choose to move them a little above to be part of the
// comments of a piece of the CST.
// This will have a global effect in the formatter.

extern {
    type Location = usize;
    type Error = lexer::LexerError;

    enum lexer::Token {
      "?" => lexer::Token::Interrogation(TokenInfo)
      ,"!" => lexer::Token::Exclamation(TokenInfo)
      ,"#" => lexer::Token::Hash(TokenInfo)
      ,"," => lexer::Token::Comma(TokenInfo)
      ,":" => lexer::Token::Colon(TokenInfo)
      ,";" => lexer::Token::StatementEnd(TokenInfo)
      ,"." => lexer::Token::Dot(TokenInfo)
      ,"::" => lexer::Token::ModuleSeparator(TokenInfo)
      ,"-" => lexer::Token::Minus(TokenInfo)
      ,"|>" => lexer::Token::CompositionLeft(TokenInfo)
      ,"<|" => lexer::Token::CompositionRight(TokenInfo)
      ,"+" => lexer::Token::Plus(TokenInfo)
      ,"^" => lexer::Token::Power(TokenInfo)
      ,"*" => lexer::Token::Star(TokenInfo)
      ,"/" => lexer::Token::Div(TokenInfo)
      ,"%" => lexer::Token::Module(TokenInfo)
      ,"<<" => lexer::Token::ShiftLeft(TokenInfo)
      ,">>" => lexer::Token::ShiftRigth(TokenInfo)
      //TODO: Add "<&>" = \ x y -> y $ x
      ,"<$>" => lexer::Token::Map(TokenInfo)
      ,"$>" => lexer::Token::MapConstRigth(TokenInfo)
      ,"<$" => lexer::Token::MapConstLeft(TokenInfo)
      //TODO: add <|> and <?>
      ,"<*>" => lexer::Token::Appliative(TokenInfo)
      ,"*>" => lexer::Token::ApplicativeRight(TokenInfo)
      ,"<*" => lexer::Token::ApplicativeLeft(TokenInfo)
      ,"==" => lexer::Token::Equality(TokenInfo)
      ,"!=" => lexer::Token::NotEqual(TokenInfo)
      ,"<=" => lexer::Token::LessOrEqual(TokenInfo)
      ,">=" => lexer::Token::MoreOrEqual(TokenInfo)
      ,"<" => lexer::Token::LessThan(TokenInfo)
      ,">" => lexer::Token::MoreThan(TokenInfo)
      ,"&&" => lexer::Token::And(TokenInfo)
      ,"||" => lexer::Token::Or(TokenInfo)
      ,"&" => lexer::Token::ReverseAppliation(TokenInfo)
      ,"$" => lexer::Token::DollarApplication(TokenInfo)
      ,"=" => lexer::Token::Asignation(TokenInfo)
      ,"@" => lexer::Token::At(TokenInfo)
      ,"|" => lexer::Token::Pipe(TokenInfo)
      ,"(" => lexer::Token::LParen(TokenInfo)
      ,")" => lexer::Token::RParen(TokenInfo)
      ,"{" => lexer::Token::LBrace(TokenInfo)
      ,"}" => lexer::Token::RBrace(TokenInfo)
      ,"[" => lexer::Token::LBracket(TokenInfo)
      ,"]" => lexer::Token::RBracket(TokenInfo)
      ,"->" => lexer::Token::RightArrow(TokenInfo)
      ,"<-" => lexer::Token::LeftArrow(TokenInfo)
      ,"\\" => lexer::Token::LambdaStart(TokenInfo)
      ,"let" => lexer::Token::Let(TokenInfo)
      ,"in" => lexer::Token::In(TokenInfo)
      ,"case" => lexer::Token::Case(TokenInfo)
      ,"of" => lexer::Token::Of(TokenInfo)
      ,"import" => lexer::Token::Import(TokenInfo)
      ,"export" => lexer::Token::Export(TokenInfo)
      ,"data" => lexer::Token::Data(TokenInfo)
      ,"newtype" => lexer::Token::Newtype(TokenInfo)
      ,"newinstance" => lexer::Token::Newtype(TokenInfo)
      ,"class" => lexer::Token::Newtype(TokenInfo)
      ,"instance" => lexer::Token::Newtype(TokenInfo)
      ,"public" => lexer::Token::Newtype(TokenInfo)
      ,"alias" => lexer::Token::Alias(TokenInfo)
      ,"as" => lexer::Token::As(TokenInfo)
      ,"unqualified" => lexer::Token::Unqualified(TokenInfo)
      ,"forall" => lexer::Token::Forall(TokenInfo)
      ,"type" => lexer::Token::Type(TokenInfo)
      ,U8 => lexer::Token::U8(TokenInfo)
      ,U16 => lexer::Token::U16(TokenInfo)
      ,U32 => lexer::Token::U32(TokenInfo)
      ,U64 => lexer::Token::U64(TokenInfo)
      ,I8 => lexer::Token::I8(TokenInfo)
      ,I16 => lexer::Token::I16(TokenInfo)
      ,I32 => lexer::Token::I32(TokenInfo)
      ,I64 => lexer::Token::I64(TokenInfo)
      ,F32 => lexer::Token::F32(TokenInfo)
      ,F64 => lexer::Token::F64(TokenInfo)
      ,LastComments=> lexer::Token::LastComments(TokenInfo,Comment)
      ,StringLiteral => lexer::Token::StringLiteral(TokenInfo,String)
      ,CharacterLiteral => lexer::Token::CharacterLiteral(TokenInfo,String)
      ,UintLiteral => lexer::Token::UintLiteral(TokenInfo,String)
      ,UFloatLiteral=> lexer::Token::UFloatLiteral(TokenInfo,String)
      ,Identifier=> lexer::Token::Identifier(TokenInfo,String)
      ,InfixIdentifier=> lexer::Token::InfixIdentifier(TokenInfo,String)
      ,Selector=> lexer::Token::Selector(TokenInfo,String)
      ,"_"=> lexer::Token::AnonHole(TokenInfo,String)
      ,NamedHole=> lexer::Token::NamedHole(TokenInfo,String)
      ,ModuleLogicPath=> lexer::Token::ModuleLogicPath(TokenInfo,String)
    }
}

// --------------------- Macros ---------------------

separated_list<T,sep>: TrailingList<T> ={
  <t:T> <mut acc: (sep T)*>=> (t,acc,None).into()
  };

terminated_list<T,sep> : TrailingList<T> =
  <t:T> <mut acc: (sep T)*> <s:sep>=> (t,acc,Some(s)).into();

trailing_list<T,sep> : TrailingList<T> = {separated_list<T,sep>,terminated_list<T,sep>}

between<left,T,right> : Between<T> =
  <l:left> <t:T> <r:right>
  => Between{left:l.into(),right:r.into(),value:t};

tuple<T> : Between<TrailingList<T>> = {
  between<"(",terminated_list<T,",">,")"> => <>,
};

record<record_item, sep> : Between<TrailingList<record_item>> = {
  between<"{",trailing_list<record_item,sep>,"}"> => <>,
};

boxed<T> : Box<T> = T => Box::new(<>);

// --------------------- Terminal translation ---------------------

pub string :Token<String> = StringLiteral =>? lexer::string_token_to_token(<>);

character : Token<char> = CharacterLiteral =>? lexer::char_token_to_token(<>);

module_path : Token<ModuleLogicPath>  =
  ModuleLogicPath =>? lexer::module_token_to_token(<>);

identifier : Token<Identifier> = Identifier =>? lexer::identifier_token_to_token(<>);
operator_name : Token<OperatorName> = {
      "?" => cst::Token{value: OperatorName::Interrogation,info:<>.into()}
      ,"!" => cst::Token{value: OperatorName::Exclamation,info:<>.into()}
      ,"#" => cst::Token{value: OperatorName::Hash,info:<>.into()}
      ,"," => cst::Token{value: OperatorName::Comma,info:<>.into()}
      ,":" => cst::Token{value: OperatorName::Colon,info:<>.into()}
      ,";" => cst::Token{value: OperatorName::StatementEnd,info:<>.into()}
      ,"." => cst::Token{value: OperatorName::Dot,info:<>.into()}
      ,"::" => cst::Token{value: OperatorName::ModuleSeparator,info:<>.into()}
      ,"-" => cst::Token{value: OperatorName::Minus,info:<>.into()}
      ,"|>" => cst::Token{value: OperatorName::CompositionLeft,info:<>.into()}
      ,"<|" => cst::Token{value: OperatorName::CompositionRight,info:<>.into()}
      ,"+" => cst::Token{value: OperatorName::Plus,info:<>.into()}
      ,"^" => cst::Token{value: OperatorName::Power,info:<>.into()}
      ,"*" => cst::Token{value: OperatorName::Star,info:<>.into()}
      ,"/" => cst::Token{value: OperatorName::Div,info:<>.into()}
      ,"%" => cst::Token{value: OperatorName::Module,info:<>.into()}
      ,"<<" => cst::Token{value: OperatorName::ShiftLeft,info:<>.into()}
      ,">>" => cst::Token{value: OperatorName::ShiftRigth,info:<>.into()}
      //TODO: Add "<&>" = \ x y -> y $ x
      ,"<$>" => cst::Token{value: OperatorName::Map,info:<>.into()}
      ,"$>" => cst::Token{value: OperatorName::MapConstRigth,info:<>.into()}
      ,"<$" => cst::Token{value: OperatorName::MapConstLeft,info:<>.into()}
      //TODO: add <|> and <?>
      ,"<*>" => cst::Token{value: OperatorName::Appliative,info:<>.into()}
      ,"*>" => cst::Token{value: OperatorName::ApplicativeRight,info:<>.into()}
      ,"<*" => cst::Token{value: OperatorName::ApplicativeLeft,info:<>.into()}
      ,"==" => cst::Token{value: OperatorName::Equality,info:<>.into()}
      ,"!=" => cst::Token{value: OperatorName::NotEqual,info:<>.into()}
      ,"<=" => cst::Token{value: OperatorName::LessOrEqual,info:<>.into()}
      ,">=" => cst::Token{value: OperatorName::MoreOrEqual,info:<>.into()}
      ,"<" => cst::Token{value: OperatorName::LessThan,info:<>.into()}
      ,">" => cst::Token{value: OperatorName::MoreThan,info:<>.into()}
      ,"&&" => cst::Token{value: OperatorName::And,info:<>.into()}
      ,"||" => cst::Token{value: OperatorName::Or,info:<>.into()}
      ,"&" => cst::Token{value: OperatorName::ReverseAppliation,info:<>.into()}
      ,"$" => cst::Token{value: OperatorName::DollarApplication,info:<>.into()}
      ,"=" => cst::Token{value: OperatorName::Asignation,info:<>.into()}
      ,"@" => cst::Token{value: OperatorName::At,info:<>.into()}
      ,"|" => cst::Token{value: OperatorName::Pipe,info:<>.into()}
      ,"->" => cst::Token{value: OperatorName::RightArrow,info:<>.into()}
      ,"<-" => cst::Token{value: OperatorName::LeftArrow,info:<>.into()}
      ,"\\" => cst::Token{value: OperatorName::LambdaStart,info:<>.into()}
};

//We can hack the lexer to do the split of the path from the
//head, but we choose to do this instead.
//We may consider the other approach if we get a conflict in lalrpop.
imported_variable : Token<ImportedVariable> =
  module_path => {
  todo!()
  //let (maybe_remain,head) = <>.split_head();
  //// The regex in the lexer is `(identifier ::)+ identifier`
  //let remain = maybe_remain.unwrap();
  //NamedVariable::PrefixedVariable{prefix:remain,name:head}
  };

//The comments right before or after the last :: are moved to be before the
// module prefix and we do the same to the before comments on the operator.
// The only part of the operator comments that is preserved is the after
// comment if it exists.
// ```
// {- original comment before -}
// a::b::c -- some comment0
//   -- some comment1
//   :: -- some comment2
// {- some comment3 -}
//      +++  -- some comment4
// ```
// Becomes
// ```
// {- original comment before -}
// -- some comment0
// -- some comment1
// -- some comment2
// {- some comment3 -}
// a::b::c::++ -- some comment4
// ```
// in the CST
// Note that the lexer prevents comments before or after the others ::
imported_operator : Token<NamedVariable> =
  <prefix:module_path> <sep:":"> <operator:operator_name>
  =>
  {
  //TODO finish this.
  //let Token{value:prefix_path, info: TokenInfo{prefix_span,token_info}} = prefix;
  //let info = prefix_info.move_after_to_before();
  //let CommentsInfo()
  //info.extend(sep.info.before);
  //info.push(sep.info.after);
  //cst::Token{ value:NamedVariable::PrefixedOperator{prefix,operator,separator:sep.info} , info:}
  todo!()
  };

local_variable : Token<Identifier> =
  identifier => <>
  ;



import_item : ImportItem ={
  identifier => ImportItem::Variable(<>),
  operator_name => ImportItem::Operator(<>),
  <t:"type"> <o:operator_name> => ImportItem::TypeOperator(t.into(),o)
};


// --------------------- Imports ---------------------

//TODO: Add importation of constructors


import_list : TrailingList<ImportItem> =
  trailing_list<import_item,","> => <>;

import_as : (TokenInfo,Token<ModuleLogicPath>) =
  <a:"as"> <p:module_path>
  => (a.into(),p);

pub import_declaration : Import =
  <import:"import"> <unqualified:"unqualified"?> <module_path:module_path>
  <import_list:between<"(",<l:import_list>,")">?>
  <qualified_path:import_as?>
  => Import{
    import:import.into(),
    unqualified:unqualified.map(|x| x.into())
    ,module_path,import_list,qualified_path};


//TODO: add kinds,
// we eventually would add type functions
// and for them enforce a termination checker
// Kinds would be useful for that.
// Additionally consider if we would add effects!

//Types

type_base : Token<TypeBase> = {
  //TODO: Delayed until enabled in the lexer
  U8 => {
    let info :TokenInfo = <>.into();
    cst::Token{value:TypeBase::U8,info}
    },
  U16 => {
    let info :TokenInfo = <>.into();
    cst::Token{value:TypeBase::U16,info}
    },
  U32 => {
    let info :TokenInfo = <>.into();
    cst::Token{value:TypeBase::U32,info}
    },
  U64 => {
    let info :TokenInfo = <>.into();
    cst::Token{value:TypeBase::U64,info}
    },
  I8 => {
    let info :TokenInfo = <>.into();
    cst::Token{value:TypeBase::I8,info}
    },
  I16 => {
    let info :TokenInfo = <>.into();
    cst::Token{value:TypeBase::I16,info}
    },
  I32 => {
    let info :TokenInfo = <>.into();
    cst::Token{value:TypeBase::I32,info}
    },
  I64 => {
    let info :TokenInfo = <>.into();
    cst::Token{value:TypeBase::I64,info}
    },
  F32 => {
    let info :TokenInfo = <>.into();
    cst::Token{value:TypeBase::F32,info}
    },
  F64 => {
    let info :TokenInfo = <>.into();
    cst::Token{value:TypeBase::F64,info}
    },
};

type_variable : Type = {
  local_variable => Type::LocalVariable(<>),
  imported_variable =>Type::ImportedVariable(<>),
};

type_tuple : Type = {
  tuple<boxed<type_expression>> => Type::Tuple(<>),
}

//TODO: add support for keyword scape
type_record_item : TypeRecordItem = {
  <variable:local_variable> <separator:":"> <expression:type_expression>
  => TypeRecordItem{
    variable,separator:separator.into(),expression:Box::new(expression)
  },
};

//TODO: add support for row polymorphism (we need kinds)
// we may need a different rule than the macro `record`
type_record : Between<TrailingList<TypeRecordItem>> = {
  record<type_record_item, ",">
};

type_atom : Type = {
  type_base => Type::Base(<>),
  type_variable => <>,
  type_tuple => <>,
  type_record => Type::Record(<>),
  <l:"("> <t:type_expression> <r:")"> => Type::Parens(
    Between{
    left : l.into(),
    right : r.into(),
    value: Box::new(t)
    }
  ),
};

type_application : Type = {
   <start:type_atom>
   <second:type_atom>
   <remain:type_atom*> => {
    Type::Application{
      start: Box::new(start) ,
      second: Box::new(second),
      remain
    }
   },
   type_atom => <>,
};

type_arrow : Type = {
  <first:type_application> <remain:("->" type_application)+>
    =>
    Type::Arrow{
      first:Box::new(first),
      remain:remain.into_iter().map(|(x,y)| (x.into(),y)  ).collect()
    },
  type_application => <>
};

type_scheme : Type = {
  <forall:"forall">
    <first_variable:local_variable>
    <remain_variables:local_variable*>
    <dot:".">
    <expression:type_arrow> => {
      Type::Scheme{
        forall: forall.into(),
        first_variable,
        remain_variables,
        dot: dot.into(),
        expression:Box::new(expression)
      }

    },
  type_arrow => <>
};

//TODO : add type operators
pub type_expression : Type = {
  type_scheme => <>,
};



// --------------------- PatternMatch  ---------------------

pattern_variable : PatternMatch = {
  local_variable => PatternMatch::LocalVariable(<>),
  imported_variable => PatternMatch::ImportedVariable(<>),
};

//TODO: add support for negative integers?
pattern_literal : PatternMatch  = {
  string => PatternMatch::String(<>),
  character => PatternMatch::Char(<>),
};

pattern_hole : PatternMatch = {
  "_" => PatternMatch::AnonHole(<>.into()),
};

pattern_tuple :PatternMatch = {
  tuple<boxed<pattern>> => PatternMatch::Tuple(<>),
};

pattern_record_item : (Token<Identifier>,Option<(TokenInfo,PatternMatch)>) = {
  <l:local_variable> <r:("=" pattern )?>  =>
  match r {
    Some((equal,p)) => (l,Some((equal.into(),p))),
    None => (l,None)
  }
  ,
}

pattern_record :PatternMatch = {
  local_variable  between<"{", trailing_list<pattern_record_item,",">,"}"> => todo!(),
  imported_variable between<"{", trailing_list<pattern_record_item,",">,"}"> => todo!(),
};


pattern_atom : PatternMatch = {
  pattern_literal => todo!(),
  pattern_variable => todo!(),
  pattern_hole => todo!(),
  pattern_tuple => todo!(),
  pattern_record => todo!(),
  between<"(",pattern,")"> => todo!(),
};

pattern_bind : PatternMatch = {
  local_variable "@" pattern_atom => todo!(),
  pattern_atom =>todo!(),
}

pattern_application :PatternMatch = {
  pattern_variable pattern_bind+ => todo!(),
  pattern_bind => todo!()
};

pub pattern : PatternMatch = {
  pattern_application => todo!(),
};


/*
// --------------------- Expression ---------------------

expression_literal : Expression ={
  string => todo!(),
  CharacterLiteral =>todo!(),
  UintLiteral =>todo!(),
  UFloatLiteral => todo!(),
};

expression_variable : Expression = {
  local_variable => todo!(),
  imported_variable => todo!(),
};

expression_named_hole : Expression = {
  NamedHole => todo!(),
};

expression_tuple : Expression = {
  tuple<expression> => todo!(),
};

expression_record_item : Expression = {
  local_variable "=" expression,
};

expression_record : Expression = {
  local_variable  between<"{", trailing_list<expression_record_item,",">,"}"> => todo!(),
}

case_item : Expression = {
  pattern "->" expression
}

//The off is needed for this:
// case some_func {a:1 , b:2} { something ...}
// the lr can't choose between
// case (some_func {a:1 , b:2}) { something ...}
// and
// (case some_func {a:1 , b:2}) { something ...}
expression_case : Expression = {
  "case" expression "of" between<"{",trailing_list<case_item,",">,"}"> => todo!(),
}


expression_atom : Expression = {
  expression_literal => todo!(),
  expression_variable => todo!(),
  expression_named_hole => todo!(),
  expression_tuple => todo!(),
  expression_record => todo!(),
  expression_case => todo!(),
  between<"(",expression,")"> => todo!(),
};

expression_selector : Expression = {
  expression_atom Selector+ => todo!(),
}

expression_argument : Expression = {
  "@" expression_atom => todo!(),
  expression_selector "?"? =>todo!(),
  expression_atom => todo!(),
}

expression_application : Expression = {
  expression_selector expression_argument* => todo!()
  expression_atom expression_argument* => todo!()
}

expression_infix_application : Expression = {
  expression_application (InfixIdentifier expression_application)? => todo!(),
}

expression_unary_operator : Expression = {
  "-" expression_infix_application => todo!(),
  "!" expression_infix_application => todo!(),
  "#" expression_infix_application => todo!(),
}

expression_composition : Expression = {
  (expression_unary_operator "|>")+ expression_unary_operator => todo!(),
  (expression_unary_operator "<|")+ expression_unary_operator => todo!(),
  expression_unary_operator => todo!(),
}

expression_exponentiation : Expression = {
  expression_composition ("^" expression_composition)? => todo!(),
}


multiplicative_operators  : Token = {
  "*" => todo!(),
  "/" => todo!(),
  "%" => todo!(),
}

expression_multiplicative : Expression = {
  expression_exponentiation
  multiplicative_operators
  expression_exponentiation
  => todo!(),
}

additive_operators : Token = {
  "+" => todo!(),
  "-" => todo!(),
}

expression_additive : Expression = {
  (expression_multiplicative additive_operators)* expression_multiplicative => todo!(),
}

expression_shift : Expression = {
  expression_additive "<<" expression_additive => todo!(),
  expression_additive ">>" expression_additive=>todo!(),
  expression_additive => todo!(),
};

expression_annotation : Expression = {
  expression_shift ":" type_expression => todo!(),
  expression_shift => todo!(),
}


functor_applicative_operators : Token<OperatorName> = {
  "<$>" => todo!(),
  "$>" => todo!(),
  "<$" => todo!(),
  "<*>" => todo!(),
  "<*" => todo!(),
  "*>" => todo!(),
}

expression_functor_applicative : Expression = {
  (expression_annotation functor_applicative_operators)* expression_annotation => todo!(),
}

comparison_operators : Token<OperatorName> = {
  "=="=>todo!()
  "!="=>todo!()
  "<="=>todo!()
  ">="=>todo!()
}

expression_comparison : Expression ={
  expression_functor_applicative
  comparison_operators
  expression_functor_applicative
  =>todo!(),
}

expression_and : Expression ={
  expression_comparison ("&&" expression_comparison)* =>todo!(),
}

expression_or : Expression = {
  expression_and ("||" expression_and)* =>todo!(),
}

expression_reverse_application : Expression = {
  (expression_composition "&")* expression_composition => todo!(),
}

expression_dollar : Expression = {
  expression_reverse_application ("$" expression_reverse_application)* => todo!()
}

// was using pattern_atom+ or separating the patterns using something like ","
// I like this more.
expression_lambda : Expression = {
  "\\" pattern_atom+ "->" expression_dollar => todo!()
  expression_dollar => todo!(),
}

let_binding : Expression = {
  pattern (":" type_expression)? "=" expression => todo!(),
}

let_bindings : Expression = {
  trailing_list<let_binding,","> =>todo!(),
}

expression_let : Expression = {
  "let" let_bindings "in" expression => todo!(),
  expression_lambda => todo!()
}

pub  expression : Expression = {
  expression_let
};



// --------------------- Data  ---------------------


pub data_type : Data = {
  "public"? "data" local_variable local_variable* "=" separated_list<(local_variable type_expression),"|">
  "public"? "data" local_variable local_variable* "="
}

pub alias : Alias = {
  "public"? "alias" local_variable local_variable* "=" type_expression
}

pub newtype : NewType = {
  "public"? "newtype" local_variable local_variable* "=" local_variable type_expression
}

pub new_instance : NewInstance = {
  "public"? "newinstance" local_variable local_variable* "=" local_variable type_expression
}


// --------------------- Class  ---------------------

//TODO: do classes need pub control?
//TODO: Support for predefined values?
//TODO: Class Constrains?
pub class : Class = {
  "public"? "class" local_variable local_variable* between<"{",trailing_list<function_declaration,",">,"}">
}


//TODO: Add support to declare the explicit type of the function
pub instance : Instance = {
  "public"? "instance" local_variable local_variable local_variable between<"{",trailing_list<function_definition,",">,"}">
  "public"? "instance" operator_name local_variable local_variable between<"{",trailing_list<function_definition,",">,"}">
  "public"? "instance" operator_name local_variable between<"{",trailing_list<function_definition,",">,"}">
}

// --------------------- Functions  ---------------------

pub function_declaration : FunctionDeclaration = {
  local_variable ":" type_expression
}


//TODO: replace local_variable* with pattern_atom*
// ie, support for patterns
pub function_definition : FunctionDefinition = {
  local_variable local_variable* "=" expression
}



pub top_non_import_item : TopItem = {
  data_type,
  alias,
  newtype,
  new_instance,
}

pub top : Cst = {
  terminated_list<import_declaration,";">?
  terminated_list<top_non_import_item,";">?
  LastComments?
}
*/
